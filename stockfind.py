import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import io
import numpy as np
import time
import re
from datetime import datetime

# í˜ì´ì§€ ì„¤ì • (ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ìµœì í™”)
st.set_page_config(page_title="ì£¼ì‹ ìŠ¤ìºë„ˆ", layout="wide")

# -------------------------
# í¬ë¡¤ë§ ë°©ì§€ ì„¤ì •
# -------------------------
def get_headers():
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Referer': 'https://finance.naver.com/'
    }

# -------------------------
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ë”œë ˆì´ ê°•í™”)
# -------------------------
def get_market_sum_pages(pages, market="KOSPI"):
    sosok = 0 if market == "KOSPI" else 1
    codes, names, changes = [], [], []

    for page in pages:
        url = f"https://finance.naver.com/sise/sise_market_sum.naver?sosok={sosok}&page={page}"
        try:
            res = requests.get(url, headers=get_headers())
            res.encoding = 'euc-kr'
            soup = BeautifulSoup(res.text, 'html.parser')
            table = soup.select_one('table.type_2')
            
            if not table: continue

            for tr in table.select('tr'):
                tds = tr.find_all('td')
                if len(tds) < 5: continue
                a = tr.find('a', href=True)
                if not a: continue
                
                code = re.search(r'code=(\d{6})', a['href']).group(1)
                name = a.get_text(strip=True)
                span = tds[4].find('span')
                change = span.get_text(strip=True) if span else '0'
                
                codes.append(code)
                names.append(name)
                changes.append(change)
            
            # í˜ì´ì§€ ì „í™˜ ê°„ ë„‰ë„‰í•œ íœ´ì‹ (2~3ì´ˆ)
            time.sleep(2.5) 
        except Exception as e:
            st.error(f"ëª©ë¡ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            
    return pd.DataFrame({'ì¢…ëª©ì½”ë“œ': codes, 'ì¢…ëª©ëª…': names, 'ë“±ë½ë¥ (%)': changes})

def get_price_data(code, max_pages=15):
    url = f"https://finance.naver.com/item/sise_day.naver?code={code}"
    dfs = []
    for page in range(1, max_pages+1):
        pg_url = f"{url}&page={page}"
        res = requests.get(pg_url, headers=get_headers())
        try:
            df = pd.read_html(io.StringIO(res.text), encoding='euc-kr')[0]
            dfs.append(df)
        except:
            continue
        # í˜ì´ì§€ë³„ 0.5~1ì´ˆ ëœë¤ ë”œë ˆì´
        time.sleep(np.random.uniform(0.5, 1.0))
        
    if not dfs: return pd.DataFrame()
    df = pd.concat(dfs, ignore_index=True).dropna(how='all')
    df = df.rename(columns=lambda x: x.strip())
    for col in ['ì¢…ê°€','ì‹œê°€','ê³ ê°€','ì €ê°€','ê±°ë˜ëŸ‰']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',',''), errors='coerce')
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
    return df.dropna(subset=['ë‚ ì§œ','ì¢…ê°€']).sort_values('ë‚ ì§œ').reset_index(drop=True)

# -------------------------
# ë¶„ì„ ë¡œì§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
# -------------------------
def analyze_stock(code, name):
    df = get_price_data(code)
    if len(df) < 40: return None
    
    # ì§€í‘œ ê³„ì‚°
    df['20MA'] = df['ì¢…ê°€'].rolling(20).mean()
    df['vol_ma5'] = df['ê±°ë˜ëŸ‰'].rolling(5).mean()
    
    # MACD
    ema12 = df['ì¢…ê°€'].ewm(span=12, adjust=False).mean()
    ema26 = df['ì¢…ê°€'].ewm(span=26, adjust=False).mean()
    df['MACD_hist'] = (ema12 - ema26) - (ema12 - ema26).ewm(span=9, adjust=False).mean()

    last = df.iloc[-1]
    prev = df.iloc[-2]
    
    # ì¡°ê±´ ì²´í¬
    price = last['ì¢…ê°€']
    ma20 = last['20MA']
    macd_last = last['MACD_hist']
    macd_prev = prev['MACD_hist']
    
    status = "ê´€ë§"
    if price > ma20 and macd_last > 0: status = "í™€ë“œ"
    if prev['ì¢…ê°€'] < prev['20MA'] and price > ma20 and macd_last > 0:
        status = "ì ê·¹ ë§¤ìˆ˜" if last['ê±°ë˜ëŸ‰'] > last['vol_ma5'] * 1.2 else "ë§¤ìˆ˜ ê´€ì‹¬"
    if price < ma20 and macd_last < macd_prev: status = "ì ê·¹ ë§¤ë„"

    return [code, name, price, round(ma20, 0), status]

# -------------------------
# Streamlit UI
# -------------------------
st.title("ğŸš€ ì‹¤ì „ 20ì¼ì„  ìŠ¤ìºë„ˆ")
st.sidebar.header("ì„¤ì •")

market = st.sidebar.radio("ì‹œì¥ ì„ íƒ", ["KOSPI", "KOSDAQ"])
page_range = st.sidebar.slider("ê°€ì ¸ì˜¬ í˜ì´ì§€ ìˆ˜", 1, 5, 1)

if st.sidebar.button("ìŠ¤ìº” ì‹œì‘"):
    st.write(f"### {market} ë¶„ì„ ì¤‘... (ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ì²œì²œíˆ ì§„í–‰í•©ë‹ˆë‹¤)")
    
    market_df = get_market_sum_pages(range(1, page_range + 1), market)
    results = []
    
    progress_bar = st.progress(0)
    for i, (idx, row) in enumerate(market_df.iterrows()):
        res = analyze_stock(row['ì¢…ëª©ì½”ë“œ'], row['ì¢…ëª©ëª…'])
        if res:
            results.append(res)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        progress_bar.progress((i + 1) / len(market_df))
        # ì¢…ëª©ê°„ ë”œë ˆì´ (1.5~2.5ì´ˆë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •)
        time.sleep(np.random.uniform(1.5, 2.5))
        
    final_df = pd.DataFrame(results, columns=['ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', '20ì¼ì„ ', 'ìƒíƒœ'])
    
    # ê²°ê³¼ ì¶œë ¥
    st.write("### ë¶„ì„ ê²°ê³¼")
    st.dataframe(final_df.style.applymap(
        lambda x: 'color: red' if 'ë§¤ìˆ˜' in str(x) else ('color: blue' if 'ë§¤ë„' in str(x) else ''),
        subset=['ìƒíƒœ']
    ), use_container_width=True)

    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    csv = final_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ(CSV)", csv, "result.csv", "text/csv")

